{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2cf9e55",
   "metadata": {},
   "source": [
    "# Odporność modeli na zakłócenia (Robustness – ImageNet-C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b97ddd0",
   "metadata": {},
   "source": [
    "## Instalacja bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "!pip install -q pytorch-lightning torchvision codecarbon scikit-learn pillow kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e61518",
   "metadata": {},
   "source": [
    "## Pobranie danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive, files\n",
    "files.upload() # Służy do umieszczenia pliku kaggle.json\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv /content/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download sautkin/imagenet1kvalid\n",
    "!unzip -q /content/imagenet1kvalid.zip -d /content/imagenet1kv1_valid\n",
    "\n",
    "!mkdir -p /content/robustness\n",
    "!tar -xvf /content/drive/MyDrive/digital.tar -C /content/robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb1edf",
   "metadata": {},
   "source": [
    "## Importy i konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from codecarbon import EmissionsTracker\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.amp import autocast\n",
    "\n",
    "from torchvision.models import (\n",
    "    efficientnet_v2_s, EfficientNet_V2_S_Weights,\n",
    "    resnet50, ResNet50_Weights,\n",
    "    densenet201, DenseNet201_Weights,\n",
    "    convnext_tiny, ConvNeXt_Tiny_Weights,\n",
    "    mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    ")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "MODELS = [\n",
    "    (efficientnet_v2_s,   EfficientNet_V2_S_Weights.IMAGENET1K_V1),\n",
    "    (resnet50,            ResNet50_Weights.IMAGENET1K_V1),\n",
    "    (densenet201,         DenseNet201_Weights.IMAGENET1K_V1),\n",
    "    (convnext_tiny,       ConvNeXt_Tiny_Weights.IMAGENET1K_V1),\n",
    "    (mobilenet_v3_large,  MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4bc2c",
   "metadata": {},
   "source": [
    "## Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loader(model, loader, device):\n",
    "    all_preds, all_trues = [], []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                logits = model(x)\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_trues.append(y.numpy())\n",
    "    return np.hstack(all_preds), np.hstack(all_trues)\n",
    "\n",
    "\n",
    "def run_robustness(corruption, model, weights, f1_clean,\n",
    "                   device, base_dir=\"/content/robustness\", batch_size=128):\n",
    "    transform = weights.transforms()\n",
    "    stats = []\n",
    "\n",
    "    print(f\"\\n>>> Robustness test: {corruption}\")\n",
    "    for sev in range(1, 6):\n",
    "        path = os.path.join(base_dir, corruption, str(sev))\n",
    "        loader = DataLoader(\n",
    "            ImageFolder(path, transform=transform),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=os.cpu_count(),\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "            prefetch_factor=4\n",
    "        )\n",
    "\n",
    "        _ = next(iter(loader))\n",
    "\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        tracker = EmissionsTracker(\n",
    "            project_name=f\"robust_{corruption}_sev{sev}\",\n",
    "            log_level=\"error\"\n",
    "        )\n",
    "        tracker.start()\n",
    "        t0 = time.time()\n",
    "\n",
    "        y_pred, y_true = evaluate_loader(model, loader, device)\n",
    "\n",
    "        duration = time.time() - t0\n",
    "        co2 = tracker.stop()\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        ce = 1 - (f1 / f1_clean)\n",
    "\n",
    "        peak_mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "        print(f\"Severity {sev} -> Czas: {duration:.1f}s | CO2: {co2:.4f}kg | Peak mem: {peak_mem:.0f} MiB\")\n",
    "\n",
    "        stats.append({\n",
    "            \"severity\": sev,\n",
    "            \"f1\": round(f1, 3),\n",
    "            \"corruption_err\": round(ce, 3)\n",
    "        })\n",
    "\n",
    "    mce = np.mean([s[\"corruption_err\"] for s in stats])\n",
    "    stats.append({\"severity\": \"mCE\", \"mce\": round(mce, 3)})\n",
    "    stats.append({\"severity\": \"clean_error\", \"value\": round(1 - f1_clean, 3)})\n",
    "\n",
    "    print(pd.DataFrame(stats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f3061",
   "metadata": {},
   "source": [
    "## Uruchomienie testów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 128\n",
    "\n",
    "# Dostępne typy zakłóceń w podzbiorze digital: elastic_transform, jpeg_compression, contrast, pixelate\n",
    "corruptions = [\"elastic_transform\"]  # Można podać wiele jednocześnie, np: [\"jpeg_compression\", \"contrast\"]\n",
    "\n",
    "for model_fn, weights in MODELS:\n",
    "    print(f\"\\n>>> Czysty F1 dla {model_fn.__name__}\")\n",
    "    model = model_fn(weights=weights).to(device)\n",
    "    model = torch.compile(model)\n",
    "\n",
    "    transform_clean = weights.transforms()\n",
    "    clean_ds = ImageFolder(\"/content/imagenet1kv1_valid\", transform=transform_clean)\n",
    "    clean_loader = DataLoader(\n",
    "        clean_ds, batch_size=batch_size,\n",
    "        num_workers=os.cpu_count(),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=4\n",
    "    )\n",
    "\n",
    "    y_pred, y_true = evaluate_loader(model, clean_loader, device)\n",
    "    peak_mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "    f1_clean = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    print(f\"Bazowe F1: {f1_clean:.4f}\")\n",
    "\n",
    "    for corruption in corruptions:\n",
    "        run_robustness(corruption, model, weights, f1_clean, device)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
