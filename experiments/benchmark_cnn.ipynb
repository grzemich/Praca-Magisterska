{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b60ec9",
   "metadata": {},
   "source": [
    "# Benchmark modeli CNN na ImageNet v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59eee21",
   "metadata": {},
   "source": [
    "## Instalacja bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "!pip install -q pytorch-lightning torchvision codecarbon scikit-learn pillow torchprofile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744876c8",
   "metadata": {},
   "source": [
    "## Pobranie danych ImageNet v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55772681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files  \n",
    "files.upload() # Służy do umieszczenia pliku kaggle.json\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv /content/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download sautkin/imagenet1kvalid\n",
    "!unzip /content/imagenet1kvalid.zip -d /content/imagenet1kv1_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e515b",
   "metadata": {},
   "source": [
    "## Importy i konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbb463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.models import (\n",
    "    efficientnet_v2_s, EfficientNet_V2_S_Weights,\n",
    "    resnet50, ResNet50_Weights,\n",
    "    densenet201, DenseNet201_Weights,\n",
    "    convnext_tiny, ConvNeXt_Tiny_Weights,\n",
    "    mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    ")\n",
    "from codecarbon import EmissionsTracker\n",
    "from sklearn.metrics import f1_score, log_loss, roc_auc_score, accuracy_score\n",
    "from torchprofile import profile_macs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "imagenet_path = \"/content/imagenet1kv1_valid\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_sizes = [128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d32e6",
   "metadata": {},
   "source": [
    "## Konfiguracja modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd89785",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS = {\n",
    "    \"efficientnet_v2_s\":  (efficientnet_v2_s,   EfficientNet_V2_S_Weights.IMAGENET1K_V1),\n",
    "    \"resnet50\":           (resnet50,            ResNet50_Weights.IMAGENET1K_V1),\n",
    "    \"densenet201\":        (densenet201,         DenseNet201_Weights.IMAGENET1K_V1),\n",
    "    \"convnext_tiny\":      (convnext_tiny,       ConvNeXt_Tiny_Weights.IMAGENET1K_V1),\n",
    "    \"mobilenet_v3_large\": (mobilenet_v3_large,  MobileNet_V3_Large_Weights.IMAGENET1K_V1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca3547",
   "metadata": {},
   "source": [
    "## Funkcja przygotowująca DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce657c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(model_weights, batch_size):\n",
    "    transform = model_weights.transforms()\n",
    "    ds = datasets.ImageFolder(imagenet_path, transform=transform)\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=min(os.cpu_count() // 2, batch_size),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e3d18",
   "metadata": {},
   "source": [
    "## Benchmark modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, (model_fn, weights) in MODEL_CONFIGS.items():\n",
    "    for bs in batch_sizes:\n",
    "        model = model_fn(weights=weights).to(device).eval()\n",
    "        num_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "        example = torch.randn(1, 3, 224, 224).to(device)\n",
    "        with torch.no_grad():\n",
    "            macs = profile_macs(model, example)\n",
    "\n",
    "        loader = get_dataloader(weights, bs)\n",
    "\n",
    "        if os.path.exists(\"/tmp/.codecarbon.lock\"):\n",
    "            os.remove(\"/tmp/.codecarbon.lock\")\n",
    "        tracker = EmissionsTracker(project_name=f\"{model_name}_bs{bs}\", log_level=\"error\")\n",
    "        tracker.start()\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "        t0 = time.time()\n",
    "\n",
    "        all_probs = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        n_images = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                probs = F.softmax(out, dim=1)\n",
    "                preds = probs.argmax(dim=1)\n",
    "\n",
    "                all_probs.append(probs.cpu().numpy())\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_labels.append(y.cpu().numpy())\n",
    "                n_images += x.size(0)\n",
    "\n",
    "        duration = time.time() - t0\n",
    "        peak_mem = torch.cuda.max_memory_allocated() / 1024**2 if device == \"cuda\" else 0\n",
    "        co2_kg = tracker.stop()\n",
    "\n",
    "        probs = np.vstack(all_probs)\n",
    "        preds = np.hstack(all_preds)\n",
    "        labels = np.hstack(all_labels)\n",
    "\n",
    "        f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        ll = log_loss(labels, probs, labels=list(range(1000)))\n",
    "        try:\n",
    "            auroc = roc_auc_score(labels, probs, multi_class=\"ovr\")\n",
    "        except:\n",
    "            auroc = float(\"nan\")\n",
    "\n",
    "        throughput = n_images / duration\n",
    "        latency_ms_img = (duration / n_images) * 1000\n",
    "\n",
    "        results.append({\n",
    "            \"model\":               model_name,\n",
    "            \"num_params\":          num_params,\n",
    "            \"macs_million\":        macs,\n",
    "            \"accuracy\":            acc,\n",
    "            \"f1_macro\":            f1,\n",
    "            \"auroc\":               auroc,\n",
    "            \"logloss\":             ll,\n",
    "            \"time_s\":              duration,\n",
    "            \"throughput_img_s\":    throughput,\n",
    "            \"latency_ms_img\":      latency_ms_img,\n",
    "            \"peak_mem_mib\":        peak_mem,\n",
    "            \"co2_kg\":              co2_kg,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13d5dc",
   "metadata": {},
   "source": [
    "## Wyświetlenie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b351b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
