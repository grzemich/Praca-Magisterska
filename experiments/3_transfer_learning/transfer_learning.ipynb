{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8ae2001c",
      "metadata": {
        "id": "8ae2001c"
      },
      "source": [
        "# Transfer Learning – ImageNet-R"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51ca5a3e",
      "metadata": {
        "id": "51ca5a3e"
      },
      "source": [
        "## Instalacja zależności"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf094b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4cf094b1",
        "outputId": "205d61c5-4fa8-40bb-ac6f-2099ae8da031"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "!pip install -q torchmetrics codecarbon pytorch_lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c747fac",
      "metadata": {
        "id": "3c747fac"
      },
      "source": [
        "## Przygotowanie środowiska i danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6047161",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b6047161",
        "outputId": "79263faf-6b4d-487e-ea16-f09884237ba3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files\n",
        "files.upload() # Służy do umieszczenia pliku kaggle.json\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/transfer\n",
        "!tar -xvf /content/drive/MyDrive/imagenet-r.tar -C /content/transfer\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download sautkin/imagenet1kvalid\n",
        "!unzip /content/imagenet1kvalid.zip -d /content/imagenet1kv1_valid"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f191094",
      "metadata": {
        "id": "8f191094"
      },
      "source": [
        "## Importy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d2dee8",
      "metadata": {
        "id": "57d2dee8"
      },
      "outputs": [],
      "source": [
        "import os, time, subprocess\n",
        "import numpy as np, pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import (\n",
        "    efficientnet_v2_s, EfficientNet_V2_S_Weights,\n",
        "    resnet50, ResNet50_Weights,\n",
        "    densenet201, DenseNet201_Weights,\n",
        "    convnext_tiny, ConvNeXt_Tiny_Weights,\n",
        "    mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
        ")\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import LightningDataModule, LightningModule\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from codecarbon import EmissionsTracker\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93736105",
      "metadata": {
        "id": "93736105"
      },
      "source": [
        "## Konfiguracja modeli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5552f50b",
      "metadata": {
        "id": "5552f50b"
      },
      "outputs": [],
      "source": [
        "MODEL_CONFIGS = {\n",
        "    \"efficientnet_v2_s\":  (efficientnet_v2_s,   EfficientNet_V2_S_Weights.IMAGENET1K_V1),\n",
        "    \"resnet50\":           (resnet50,            ResNet50_Weights.IMAGENET1K_V1),\n",
        "    \"densenet201\":        (densenet201,         DenseNet201_Weights.IMAGENET1K_V1),\n",
        "    \"convnext_tiny\":      (convnext_tiny,       ConvNeXt_Tiny_Weights.IMAGENET1K_V1),\n",
        "    \"mobilenet_v3_large\": (mobilenet_v3_large,  MobileNet_V3_Large_Weights.IMAGENET1K_V1),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da1c29ed",
      "metadata": {
        "id": "da1c29ed"
      },
      "source": [
        "## LightningDataModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac54bc84",
      "metadata": {
        "id": "ac54bc84"
      },
      "outputs": [],
      "source": [
        "class TLDataModule(LightningDataModule):\n",
        "    def __init__(self, data_dir, transform, batch_size):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        full_dataset = ImageFolder(self.data_dir, transform=self.transform)\n",
        "        total_len = len(full_dataset)\n",
        "        train_len = int(0.8 * total_len)\n",
        "        val_len = total_len - train_len\n",
        "        self.train_ds, self.val_ds = random_split(\n",
        "            full_dataset, [train_len, val_len], generator=torch.Generator().manual_seed(42)\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True,\n",
        "                          num_workers=4, pin_memory=True, prefetch_factor=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False,\n",
        "                          num_workers=4, pin_memory=True, prefetch_factor=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd29f71",
      "metadata": {
        "id": "7dd29f71"
      },
      "source": [
        "## TransferModel (LightningModule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e17ced",
      "metadata": {
        "id": "01e17ced"
      },
      "outputs": [],
      "source": [
        "class TransferModel(LightningModule):\n",
        "    def __init__(self, model_fn, weights, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = model_fn(weights=weights)\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        if hasattr(self.model, \"classifier\"):\n",
        "            if isinstance(self.model.classifier, torch.nn.Sequential):\n",
        "                in_feat = self.model.classifier[-1].in_features\n",
        "                self.model.classifier[-1] = torch.nn.Linear(in_feat, num_classes)\n",
        "            elif isinstance(self.model.classifier, torch.nn.Linear):\n",
        "                in_feat = self.model.classifier.in_features\n",
        "                self.model.classifier = torch.nn.Linear(in_feat, num_classes)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported classifier type: {type(self.model.classifier)}\")\n",
        "        elif hasattr(self.model, \"fc\"):\n",
        "            in_feat = self.model.fc.in_features\n",
        "            self.model.fc = torch.nn.Linear(in_feat, num_classes)\n",
        "        elif hasattr(self.model, \"head\"):\n",
        "            in_feat = self.model.head.in_features\n",
        "            self.model.head = torch.nn.Linear(in_feat, num_classes)\n",
        "        else:\n",
        "            raise ValueError(\"Nieobsługiwana architektura – brak standardowej głowy klasyfikatora\")\n",
        "\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        self.preds, self.labels = [], []\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        preds = logits.argmax(1)\n",
        "        self.preds.append(preds.cpu())\n",
        "        self.labels.append(y.cpu())\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        preds = torch.cat(self.preds)\n",
        "        labels = torch.cat(self.labels)\n",
        "        acc = accuracy_score(labels, preds)\n",
        "        f1 = f1_score(labels, preds, average=\"macro\")\n",
        "        self.log(\"val_accuracy\", acc)\n",
        "        self.log(\"val_f1\", f1)\n",
        "        self.preds, self.labels = [], []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(filter(lambda p: p.requires_grad, self.parameters()), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be16ec2f",
      "metadata": {
        "id": "be16ec2f"
      },
      "source": [
        "## Funkcja `run_transfer_learning()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c117fb53",
      "metadata": {
        "id": "c117fb53"
      },
      "outputs": [],
      "source": [
        "def run_transfer_learning(model_name, model_fn, weights, data_dir, batch_size):\n",
        "    transform = weights.transforms()\n",
        "    dm = TLDataModule(data_dir, transform, batch_size)\n",
        "    dm.setup()\n",
        "\n",
        "    module = TransferModel(model_fn, weights, num_classes=len(dm.train_ds.dataset.classes))\n",
        "\n",
        "    params_total = sum(p.numel() for p in module.parameters())\n",
        "    params_train = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "    if os.path.exists(\"/tmp/.codecarbon.lock\"):\n",
        "        os.remove(\"/tmp/.codecarbon.lock\")\n",
        "    tracker = EmissionsTracker(project_name=f\"TL_{model_name}\", log_level=\"error\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    tracker.start()\n",
        "\n",
        "    t0 = time.time()\n",
        "    trainer = pl.Trainer(max_epochs=1, accelerator=\"gpu\", devices=1,\n",
        "                         precision=\"16-mixed\", logger=False,\n",
        "                         enable_checkpointing=False)\n",
        "    trainer.fit(module, dm)\n",
        "    train_time = time.time() - t0\n",
        "\n",
        "    t0 = time.time()\n",
        "    trainer.validate(module, datamodule=dm)\n",
        "    val_time = time.time() - t0\n",
        "\n",
        "    co2 = tracker.stop()\n",
        "    peak_mem = torch.cuda.max_memory_allocated() / 1024**2\n",
        "\n",
        "    print(f\"=== {model_name} ===\")\n",
        "    print(f\"Total params:     {params_total:,}\")\n",
        "    print(f\"Trainable params: {params_train:,}\")\n",
        "    print(f\"CO₂:               {co2:.4f} kg\")\n",
        "    print(f\"Train time:        {train_time:.1f} s\")\n",
        "    print(f\"Val time:          {val_time:.1f} s\")\n",
        "    print(f\"Peak GPU memory:   {peak_mem:.0f} MiB\")\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ce3f00",
      "metadata": {
        "id": "28ce3f00"
      },
      "source": [
        "## Uruchomienie eksperymentu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b392dd92",
      "metadata": {
        "id": "b392dd92"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/transfer/imagenet-r\"\n",
        "batch_size = 128\n",
        "\n",
        "for name, (fn, weights) in MODEL_CONFIGS.items():\n",
        "    run_transfer_learning(name, fn, weights, data_dir, batch_size)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
